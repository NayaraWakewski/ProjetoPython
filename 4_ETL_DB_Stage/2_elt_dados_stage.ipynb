{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das Bibliotecas\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Numeric, DateTime, text\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do engine do SQLAlchemy para o PostgreSQL\n",
    "engine = create_engine(\n",
    "    'postgresql://airflow:airflow@127.0.0.1:5432/airflow',\n",
    "    echo=False  # Desativado para não visualizar as instruções SQL geradas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das colunas de data e valor fora das funções para uso global - pois ao mudar os tipos de dados, não tem como criar\n",
    "# Uma função que reconheça o tipo de dados dessas colunas e classifique corretamente, como está tudo como TEXT, independente dos,\n",
    "# Valores das colunas, ele não consegue mudar o tipo de forma automatica; A forma encontrada foi criar um dicionário, com os tipos \n",
    "# das colunas que tem que ser alteradas, e nas funções abaixo usar esses dicionarios para fazer a alteração corretamente.\n",
    "colunas_de_data = [\n",
    "    'data_assinatura', 'data_processamento', 'data_termino',\n",
    "    'data_publicacao_portal', 'data_publicacao_doe', 'data_auditoria',\n",
    "    'data_termino_original', 'data_inicio', 'data_rescisao',\n",
    "    'data_finalizacao_prestacao_contas'\n",
    "]\n",
    "colunas_de_valor = [\n",
    "    'valor_contrato', 'valor_can_rstpg', 'valor_original_concedente',\n",
    "    'valor_original_contrapartida', 'valor_atualizado_concedente',\n",
    "    'valor_atualizado_contrapartida', 'calculated_valor_aditivo',\n",
    "    'calculated_valor_ajuste', 'calculated_valor_empenhado',\n",
    "    'calculated_valor_pago'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter entrada em data de forma segura\n",
    "def converter_para_datetime_seguro(coluna):\n",
    "    convertido = []\n",
    "    for entrada in coluna:\n",
    "        try:\n",
    "            data_convertida = pd.to_datetime(entrada)\n",
    "        except (ValueError, TypeError):\n",
    "            try:\n",
    "                data_convertida = parse(entrada, default=pd.NaT)\n",
    "            except (ValueError, TypeError):\n",
    "                data_convertida = pd.NaT\n",
    "        convertido.append(data_convertida)\n",
    "    return pd.Series(convertido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Função para tratar os nulos e preencher os valores\n",
    "def tratar_nulos(df):\n",
    "    print(f\"Antes do tratamento, contagem de nulos por coluna de data:\")\n",
    "    print(df[colunas_de_data].isnull().sum())\n",
    "    \n",
    "    # Tratamento para colunas de data\n",
    "    for col in colunas_de_data:\n",
    "        df[col] = converter_para_datetime_seguro(df[col])\n",
    "    \n",
    "    # Tratamento para colunas numéricas\n",
    "    for col in colunas_de_valor:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.00)\n",
    "    \n",
    "    # Tratamento para colunas de texto\n",
    "    outras_colunas = [col for col in df.columns if col not in colunas_de_data + colunas_de_valor]\n",
    "    df[outras_colunas] = df[outras_colunas].fillna(\"Não Informado\")\n",
    "    \n",
    "    # Tratamento para colunas booleanas\n",
    "    colunas_booleanas = [col for col in df.columns if df[col].dtype == 'bool']\n",
    "    df[colunas_booleanas] = df[colunas_booleanas].fillna(False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para normalizar colunas de texto para maiúsculas\n",
    "def normalizar_colunas_texto(df):\n",
    "    colunas_texto = [col for col in df.columns if col not in colunas_de_data + colunas_de_valor]\n",
    "    for col in colunas_texto:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.upper()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para remover duplicatas\n",
    "def remover_duplicatas(df):\n",
    "    numero_de_linhas_inicial = df.shape[0]\n",
    "    print(f\"Total de linhas antes da remoção de duplicatas: {numero_de_linhas_inicial}\")\n",
    "    \n",
    "    # Removendo duplicatas com base nas colunas-chave\n",
    "    df = df.drop_duplicates(subset=['cpf_cnpj_financiador', 'num_contrato', 'data_assinatura'])\n",
    "    \n",
    "    numero_de_linhas_final = df.shape[0]\n",
    "    print(f\"Total de linhas após a remoção de duplicatas: {numero_de_linhas_final}\")\n",
    "    print(f\"Duplicatas removidas: {numero_de_linhas_inicial - numero_de_linhas_final}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para extrair dados do banco de dados\n",
    "def extrair_dados(engine, esquema, nome_tabela):\n",
    "    query = f\"SELECT * FROM {esquema}.{nome_tabela};\"\n",
    "    with engine.connect() as conexao:\n",
    "        df = pd.read_sql(query, conexao)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar dados no banco de dados com tipos definidos e mapear aqueles dicionários criados lá no inicio do código.\n",
    "def carregar_dados(engine, df, esquema, nome_tabela):\n",
    "    mapeamento_de_tipos = {\n",
    "        col: DateTime() for col in colunas_de_data\n",
    "    }\n",
    "    mapeamento_de_tipos.update({\n",
    "        col: Numeric(20, 2) for col in colunas_de_valor\n",
    "    })\n",
    "    \n",
    "    with engine.begin() as conexao:\n",
    "        conexao.execute(text(f\"DROP TABLE IF EXISTS {esquema}.{nome_tabela};\"))\n",
    "        df.to_sql(nome_tabela, conexao, schema=esquema, if_exists='replace', index=False, method='multi', dtype=mapeamento_de_tipos)\n",
    "    print(f\"Dados carregados na tabela '{esquema}.{nome_tabela}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal para realizar ETL para ambas as tabelas\n",
    "def pipeline_etl(engine, esquema, nome_tabela):\n",
    "    print(f\"Iniciando ETL para {esquema}.{nome_tabela}\")\n",
    "    df = extrair_dados(engine, esquema, nome_tabela)\n",
    "    df = tratar_nulos(df)\n",
    "    df = normalizar_colunas_texto(df)\n",
    "    df = remover_duplicatas(df)\n",
    "    carregar_dados(engine, df, esquema, nome_tabela)\n",
    "    \n",
    "    # Adicionando a chave única após a carga de dados\n",
    "    with engine.begin() as conexao:\n",
    "        nome_constraint = f\"{nome_tabela}_chave_unica\"\n",
    "        sql_adicionar_constraint = text(f\"\"\"\n",
    "            ALTER TABLE {esquema}.{nome_tabela}\n",
    "            DROP CONSTRAINT IF EXISTS {nome_constraint},\n",
    "            ADD CONSTRAINT {nome_constraint} UNIQUE (cpf_cnpj_financiador, num_contrato, data_assinatura);\n",
    "        \"\"\")\n",
    "        conexao.execute(sql_adicionar_constraint)\n",
    "    print(f\"Chave única adicionada à tabela '{esquema}.{nome_tabela}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ETL para stage.contratos\n",
      "Antes do tratamento, contagem de nulos por coluna de data:\n",
      "data_assinatura                        0\n",
      "data_processamento                     0\n",
      "data_termino                           0\n",
      "data_publicacao_portal                 0\n",
      "data_publicacao_doe                    0\n",
      "data_auditoria                         0\n",
      "data_termino_original                  0\n",
      "data_inicio                            0\n",
      "data_rescisao                        495\n",
      "data_finalizacao_prestacao_contas    500\n",
      "dtype: int64\n",
      "Total de linhas antes da remoção de duplicatas: 500\n",
      "Total de linhas após a remoção de duplicatas: 477\n",
      "Duplicatas removidas: 23\n",
      "Dados carregados na tabela 'stage.contratos'\n",
      "Chave única adicionada à tabela 'stage.contratos'\n",
      "Iniciando ETL para stage.convenios\n",
      "Antes do tratamento, contagem de nulos por coluna de data:\n",
      "data_assinatura                        0\n",
      "data_processamento                     0\n",
      "data_termino                           0\n",
      "data_publicacao_portal                 0\n",
      "data_publicacao_doe                    2\n",
      "data_auditoria                         0\n",
      "data_termino_original                  1\n",
      "data_inicio                            1\n",
      "data_rescisao                        123\n",
      "data_finalizacao_prestacao_contas     94\n",
      "dtype: int64\n",
      "Total de linhas antes da remoção de duplicatas: 125\n",
      "Total de linhas após a remoção de duplicatas: 125\n",
      "Duplicatas removidas: 0\n",
      "Dados carregados na tabela 'stage.convenios'\n",
      "Chave única adicionada à tabela 'stage.convenios'\n"
     ]
    }
   ],
   "source": [
    "# Executando o ETL para as tabelas 'contratos' e 'convenios' no esquema 'stage'\n",
    "for tabela in ['contratos', 'convenios']:\n",
    "    pipeline_etl(engine, 'stage', tabela)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
